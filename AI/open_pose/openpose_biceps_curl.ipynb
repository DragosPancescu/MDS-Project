{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd06b5c15bd35a4797d28593a91f60c9e88ab21c8972a3b90ed3c6387e9c9d9c425",
   "display_name": "Python 3.8.8 64-bit ('tf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import json\n",
    "from random import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from test import validate_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOD_POSE_DIR = 'good_pose'\n",
    "BAD_POSE_DIR = 'bad_pose'\n",
    "IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_image(image):\n",
    "    \"\"\"Function to encode and give a label to an image.\n",
    "    \n",
    "    Arguments:\n",
    "        image {string} -- Represents the image name.\n",
    "\n",
    "    Returns\n",
    "        integer -- 0/1 encoding for a bad/good pose image.\n",
    "    \"\"\"\n",
    "    world_label = image.split('_')[0]\n",
    "    if world_label == 'good':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(form):\n",
    "    \"\"\"Function to process the data and save it in a numpy array form (friendlier to neural networks).\n",
    "\n",
    "    Arguments:\n",
    "        form {string} -- represents the type of images it receives.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    if form == 'good':\n",
    "        dir = os.listdir(GOOD_POSE_DIR)\n",
    "    else:\n",
    "        dir = os.listdir(BAD_POSE_DIR)\n",
    "\n",
    "    for image in dir:\n",
    "        label = label_image(image)\n",
    "        if form == 'good':\n",
    "            path = os.path.join(GOOD_POSE_DIR, image)\n",
    "        else:\n",
    "            path = os.path.join(BAD_POSE_DIR, image)\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), (IMG_SIZE, IMG_SIZE))\n",
    "        data.append([np.array(img), label])\n",
    "    \n",
    "    # Saves the data in numpy form.\n",
    "    if form == 'good':\n",
    "        np.save('data\\good_pose_data.npy', data)\n",
    "    else:\n",
    "        np.save('data\\\\bad_pose_data.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "good_pose = np.load('data\\good_pose_data.npy', allow_pickle=True)\n",
    "bad_pose = np.load('data\\\\bad_pose_data.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixing the good pose data and bad pose data\n",
    "good_and_bad_pose = np.concatenate((good_pose, bad_pose), axis=0)\n",
    "\n",
    "# Split the data in train/test.\n",
    "data = good_and_bad_pose[:, 0]\n",
    "labels = good_and_bad_pose[:, 1]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(data, labels, train_size=0.8, random_state=4)\n",
    "\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "y_valid = np.asarray(y_valid).astype(np.float32)"
   ]
  },
  {
   "source": [
    "## Running Openpose over the images to get the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weigths\n",
    "net = cv2.dnn.readNetFromTensorflow('graph_opt.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openpose_data(frame, thr=0.2):\n",
    "    \"\"\"Function to run the openpose model over an image and get the coordinates for all 19 keypoints.\n",
    "    \n",
    "    Arguments:\n",
    "        frame {list} -- The image that the openpose model is run over.\n",
    "    \n",
    "    Returns:\n",
    "        list -- A list that consists of coordinates of the keypoints.\n",
    "    \"\"\"\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    \n",
    "    net.setInput(cv2.dnn.blobFromImage(frame, 1.0, (IMG_SIZE, IMG_SIZE), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out = net.forward()\n",
    "    out = out[:, :19, :, :]\n",
    "\n",
    "    assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "    points = []\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        heatMap = out[0, i, :, :]\n",
    "\n",
    "        _, conf, _, point = cv2.minMaxLoc(heatMap)\n",
    "        x = (frameWidth * point[0]) / out.shape[3]\n",
    "        y = (frameHeight * point[1]) / out.shape[2]\n",
    "\n",
    "        points.append([int(x), int(y)] if conf > thr else None)\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_openpose_data(data, scaler, fit=True):\n",
    "    \"\"\"Functions that is processing the data output of openpose.\n",
    "\n",
    "    Arguments:\n",
    "        data {list} -- List of keypoints.\n",
    "        scaler {object} -- Scikit-learn scaler.\n",
    "        fit {boolean} -- Boolean that tells the function to fit the data before transforming.\n",
    "\n",
    "    Returns:\n",
    "        {numpy.array} -- Processed data.\n",
    "    \"\"\"\n",
    "    x_data = []\n",
    "\n",
    "    for image in data:\n",
    "        openpose_data = get_openpose_data(image)\n",
    "        for idx, coords in enumerate(openpose_data):\n",
    "            if coords == None:\n",
    "                openpose_data[idx] = [0, 0]\n",
    "        x_data.append(openpose_data[1:5])\n",
    "    \n",
    "    x_data = np.array(x_data).astype(float)\n",
    "    # Reshape so we can fit the scaler on our data.\n",
    "    x_data = x_data.reshape(x_data.shape[0], x_data.shape[1] * 2)\n",
    "    \n",
    "    # Normalize the data\n",
    "    if fit == True:\n",
    "        scaler.fit(x_data)\n",
    "    x_data = scaler.transform(x_data)\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_performance(model, f1, loss):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_openpose = process_openpose_data(X_train, scaler, fit=True)\n",
    "X_valid_openpose = process_openpose_data(X_valid, scaler, fit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualizing the keypoints\n",
    "for coords in X_train_openpose:\n",
    "    for coord, body_part in zip(coords, list(BODY_PARTS.keys())[1:5]):\n",
    "        print(f'{body_part} -> {coord}')\n",
    "    print('\\n')"
   ]
  },
  {
   "source": [
    "## The fully conected model that takes the keypoint coordinates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = f'openpose_bicepscurl_4keypoints_newdata_{int(time.time())}'\n",
    "tensorboard = TensorBoard(Logdir=f'logs/{NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(8)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "NAME = f'openpose_bicepscurl_4keypoints_newdata2_{int(time.time())}'\n",
    "tensorboard = TensorBoard(log_dir=f'logs2/{NAME}')\n",
    "model.fit(X_train_openpose, y_train, epochs=200, callbacks=[tensorboard], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_valid_openpose, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_valid, output.round()))\n",
    "print(accuracy_score(y_valid, output.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save('saved_models\\openpose_bicepscurl_8keypoints_lr0.0001')"
   ]
  },
  {
   "source": [
    "## Working on the video preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_models\\openpose_bicepscurl_8keypoints_newdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment_video(video_name, save_location, interval):\n",
    "    \"\"\"Function to fragment video into frames at a given interval of time\n",
    "        and saves the in a given directory.\n",
    "\n",
    "    Arguments:\n",
    "        video_name {string} -- Path to the video.\n",
    "        save_location {string} -- Path to the save location.\n",
    "        interval {integer} -- Interval in ms.\n",
    "    \"\"\"\n",
    "    vidcap = cv2.VideoCapture(video_name)\n",
    "    success, image = vidcap.read()\n",
    "\n",
    "    # Change the current directory if we are not already there.\n",
    "    cwd = os.getcwd()\n",
    "    if cwd != save_location:\n",
    "        os.chdir(save_location)\n",
    "\n",
    "    # While we have frames, we read and save them.\n",
    "    count = 1\n",
    "    while success:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, (count*interval))\n",
    "        cv2.imwrite(f'frame{count}.jpg', image)\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "\n",
    "    # Change the directory back.\n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames(location):\n",
    "    \"\"\"Functions that reads the video frames from a director.\n",
    "\n",
    "    Arguments:\n",
    "        location {string} -- Path to the directory where the frames are located at.\n",
    "\n",
    "    Returns:\n",
    "        {list} -- Resized video frames.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    directory = os.listdir(location)\n",
    "\n",
    "    for frame in directory:\n",
    "        path = os.path.join(location, frame)\n",
    "        frame = cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), (IMG_SIZE, IMG_SIZE))\n",
    "        frames.append(frame)\n",
    "    return np.array(frames).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_frames(location):\n",
    "    \"\"\"Functions that deletes the frames that we generated to free the memory.\n",
    "\n",
    "    Arguments:\n",
    "        location {string} -- Path to the directory where the frames are located at.\n",
    "    \"\"\"\n",
    "    directory = os.listdir(location)\n",
    "\n",
    "    for frame in directory:\n",
    "        path = os.path.join(location, frame)\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_video('D:\\College\\coding (Python)\\OpenPose - Biceps Curl\\\\videos\\\\2.mp4', 'frames', 250)\n",
    "input_data = read_frames('frames')\n",
    "delete_frames('frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_valid_video = process_openpose_data(input_data, scaler, fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(x_valid_video)"
   ]
  },
  {
   "source": [
    "## Transforming the model into a tensorflow lite model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tflite(model):\n",
    "    \"\"\"Functions that converts our keras model to a tensorflow lite model.\n",
    "\n",
    "    Arguments:\n",
    "        model {object} -- Keras model that needs to be converted.\n",
    "    \"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open('tflite_models\\model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_tflite(model)"
   ]
  },
  {
   "source": [
    "## Parsing the config file and building the model from it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config_file(location):\n",
    "    with open(location, 'r') as f:\n",
    "        model_json = json.load(f)\n",
    "    return model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_from_json(location):\n",
    "    # Read the json file\n",
    "    model_json = parse_config_file(location)\n",
    "    print(model_json)\n",
    "\n",
    "    # Validate the file\n",
    "    if not validate_config(model_json):\n",
    "        raise('Config file is not valid')\n",
    "\n",
    "    # Create the keras model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input Layers\n",
    "    model.add(Input(shape=model_json['Input']['shape']))\n",
    "    if model_json['Input']['flatten'] == True:\n",
    "        model.add(Flatten())\n",
    "\n",
    "    # Hidden Layers\n",
    "    for layer in model_json['Layers']:\n",
    "        if layer['type'] == 'dense':\n",
    "            model.add(Dense(layer['neurons'], activation=layer['activation']))\n",
    "        # else if layer['type'] == 'conv2d':\n",
    "            # model.add(Conv2d(layer['neurons'], activation=layer['activation']))\n",
    "    \n",
    "    # Optimizer\n",
    "    if model_json['Optimizer']['name'] == 'Adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=model_json['Optimizer']['learning_rate'])\n",
    "\n",
    "    # Loss and metrics\n",
    "    m = []\n",
    "    for metric in model_json['Metrics'].values():\n",
    "        m.append(metric)\n",
    "\n",
    "    model.compile(loss=model_json['Loss_function']['name'],\n",
    "                optimizer=optimizer,\n",
    "                metrics=m)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_from_json('model_config_files\\model_4dense_bc_4keypoints.hjson')"
   ]
  }
 ]
}