{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd09ec801142265f48bfcb825e32a37abe8b231fb5c14e0e720277743d1e6436416",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "from random import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras import activations\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOD_POSE_DIR = 'good_pose'\n",
    "BAD_POSE_DIR = 'bad_pose'\n",
    "IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_image(image):\n",
    "    \"\"\"\n",
    "    Function to encode and give a label to an image.\n",
    "    image : (String) -> represents the image name.\n",
    "    return : (Int) -> 0/1 encoding for a bad/good pose image.\n",
    "    \"\"\"\n",
    "    world_label = image.split('_')[0]\n",
    "    if world_label == 'good':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(form):\n",
    "    \"\"\"\n",
    "    Function to process the data and save it in a numpy array form. (friendlier to neural networks)\n",
    "    form : (String) -> represents the type of images it receives\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    if form == 'good':\n",
    "        dir = os.listdir(GOOD_POSE_DIR)\n",
    "    else:\n",
    "        dir = os.listdir(BAD_POSE_DIR)\n",
    "\n",
    "    for image in dir:\n",
    "        label = label_image(image)\n",
    "        if form == 'good':\n",
    "            path = os.path.join(GOOD_POSE_DIR, image)\n",
    "        else:\n",
    "            path = os.path.join(BAD_POSE_DIR, image)\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), (IMG_SIZE, IMG_SIZE))\n",
    "        data.append([np.array(img), label])\n",
    "    \n",
    "    if form == 'good':\n",
    "        np.save('good_pose_data.npy', data)\n",
    "    else:\n",
    "        np.save('bad_pose_data.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "good_pose = np.load('good_pose_data.npy', allow_pickle=True)\n",
    "bad_pose = np.load('bad_pose_data.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixing the good pose data and bad pose data\n",
    "good_and_bad_pose = np.concatenate((good_pose, bad_pose), axis=0)\n",
    "\n",
    "# Split the data in train/test.\n",
    "data = good_and_bad_pose[:, 0]\n",
    "labels = good_and_bad_pose[:, 1]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(data, labels, train_size=0.8)\n",
    "\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "y_valid = np.asarray(y_valid).astype(np.float32)"
   ]
  },
  {
   "source": [
    "## Running Openpose over the images to get the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.2\n",
    "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
    "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weigths\n",
    "net = cv2.dnn.readNetFromTensorflow('graph_opt.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openpose_data(frame):\n",
    "    \"\"\"\n",
    "    Function to run the openpose model over an image and get the coordonates for all 19 keypoints\n",
    "    frame: (List) -> The image\n",
    "    \"\"\"\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    \n",
    "    net.setInput(cv2.dnn.blobFromImage(frame, 1.0, (IMG_SIZE, IMG_SIZE), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out = net.forward()\n",
    "    out = out[:, :19, :, :]\n",
    "\n",
    "    assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "    points = []\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        heatMap = out[0, i, :, :]\n",
    "\n",
    "        _, conf, _, point = cv2.minMaxLoc(heatMap)\n",
    "        x = (frameWidth * point[0]) / out.shape[3]\n",
    "        y = (frameHeight * point[1]) / out.shape[2]\n",
    "\n",
    "        points.append([int(x), int(y)] if conf > thr else None)\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_openpose_data(data):\n",
    "    x_data = []\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    for idx1, image in enumerate(X_train):\n",
    "        openpose_data = get_openpose_data(image)\n",
    "        for idx2, coords in enumerate(openpose_data):\n",
    "            if coords == None:\n",
    "                openpose_data[idx2] = [0, 0]\n",
    "        if idx1 == 0:\n",
    "            scaler.fit(openpose_data)\n",
    "        openpose_data = scaler.transform(openpose_data)[:-1]\n",
    "        X_train_openpose.append(openpose_data)\n",
    "    \n",
    "    x_data = np.array(x_data).astype(float)\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_openpose = []\n",
    "X_valid_openpose = []\n",
    "\n",
    "# Get the keypoints and for the unavailable keypoints transform NoneType to 0\n",
    "# Plus we scale them [0, 1]\n",
    "for idx1, image in enumerate(X_train):\n",
    "    openpose_data = get_openpose_data(image)\n",
    "    for idx2, coords in enumerate(openpose_data):\n",
    "        if coords == None:\n",
    "            openpose_data[idx2] = [0, 0]\n",
    "    if idx1 == 0:\n",
    "        scaler.fit(openpose_data)\n",
    "    openpose_data = scaler.transform(openpose_data)[:-1]\n",
    "    X_train_openpose.append(openpose_data)\n",
    "\n",
    "for image in X_valid:\n",
    "    openpose_data = get_openpose_data(image)\n",
    "    for idx, coords in enumerate(openpose_data):\n",
    "        if coords == None:\n",
    "            openpose_data[idx] = [0, 0]\n",
    "    openpose_data = scaler.transform(openpose_data)[:-1]\n",
    "    X_valid_openpose.append(openpose_data)\n",
    " \n",
    "\n",
    "X_train_openpose = np.array(X_train_openpose).astype(float)\n",
    "X_valid_openpose = np.array(X_valid_openpose).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualizing the keypoints\n",
    "for coords in X_train_openpose:\n",
    "    for coord, body_part in zip(coords, BODY_PARTS.keys()):\n",
    "        print(f'{body_part} -> {coord}')\n",
    "    print('\\n')"
   ]
  },
  {
   "source": [
    "## The fully conected model that takes the keypoint coordinates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(18,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_openpose, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_valid_openpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_valid, output.round()))\n",
    "print(accuracy_score(y_valid, output.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save('openpose_bicepscurl_nobg')"
   ]
  },
  {
   "source": [
    "## Working on the video preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment_video(video_name, save_location, interval):\n",
    "    \"\"\"\n",
    "    video_name: String -> path to the video\n",
    "    save_location: Strin -> path to the save location\n",
    "    interval: Int -> interval in ms\n",
    "    \"\"\"\n",
    "    vidcap = cv2.VideoCapture(video_name)\n",
    "    success, image = vidcap.read()\n",
    "\n",
    "    # Change the current directory.\n",
    "    #os.chdir(save_location)\n",
    "\n",
    "    # While we have frames, we read and save them.\n",
    "    count = 1\n",
    "    while success:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, (count*interval))\n",
    "        cv2.imwrite(f'frame{count}.jpg', image)\n",
    "        success, image = vidcap.read()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames(location):\n",
    "    frames = []\n",
    "    dir = os.listdir(location)\n",
    "\n",
    "    for frame in dir:\n",
    "        path = os.path.join(location, frame)\n",
    "        frame = cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), (IMG_SIZE, IMG_SIZE))\n",
    "        frames.append(frame)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment_video('D:\\College\\coding (Python)\\PoseNet - Biceps Curl\\\\videos\\\\2.mp4', 'frames', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = read_frames('D:\\College\\coding (Python)\\PoseNet - Biceps Curl\\\\frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_video = []\n",
    "\n",
    "for image in input_data:\n",
    "    openpose_data = get_openpose_data(image)\n",
    "    for idx, coords in enumerate(openpose_data):\n",
    "        if coords == None:\n",
    "            openpose_data[idx] = [0, 0]\n",
    "    openpose_data = scaler.transform(openpose_data)[:-1]\n",
    "    x_valid_video.append(openpose_data)\n",
    "\n",
    "x_valid_video = np.array(x_valid_video).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(x_valid_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.73810977]\n [2.9458427 ]\n [2.9144278 ]\n [0.        ]\n [1.0992996 ]\n [1.7052757 ]\n [0.17849872]\n [2.9229093 ]\n [2.217883  ]\n [0.36903706]\n [0.40409335]\n [0.        ]\n [1.0808004 ]\n [0.        ]\n [1.2917217 ]\n [2.8783221 ]\n [0.        ]\n [0.39451832]\n [1.7501711 ]\n [2.046883  ]\n [2.2756276 ]\n [2.5198426 ]\n [1.5046622 ]]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ]
}